{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\envs\\pytorch\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "import csv\n",
    "import cv2\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_PATH = \"./dataset/test\"\n",
    "# device = (torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu'))\n",
    "device = \"cpu\"\n",
    "# try device = \"cuda\" \n",
    "# and change your settings/accelerator to GPU if you want it to run faster if your using kaggle's enviroment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpt_dir = './model_weights/'\n",
    "os.makedirs(cpt_dir, exist_ok=True)\n",
    "phase_dir = './results/'\n",
    "os.makedirs(phase_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphabets = \"abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789\"\n",
    "alphabets2index = {alphabet:i for i, alphabet in enumerate(alphabets)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Task1Dataset(Dataset):\n",
    "    def __init__(self, data, root, return_filename=False):\n",
    "        self.data = [sample for sample in data if sample[0].startswith(\"task1\")]\n",
    "        self.return_filename = return_filename\n",
    "        self.root = root\n",
    "        #self.transform = transforms.RandomOrder(transform)\n",
    "        self.transform = transforms.Compose([\n",
    "            #transforms.Resize(32),\n",
    "            transforms.ToTensor()\n",
    "        ])\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        filename, label = self.data[index]\n",
    "        img = cv2.imread(\"{}/{}\".format(self.root, filename))\n",
    "        img = cv2.resize(img, (96, 96))\n",
    "        img = cv2.medianBlur(img, 5)\n",
    "        img = np.mean(img, axis=2)\n",
    "        img = Image.fromarray(img)\n",
    "        img = self.transform(img)\n",
    "        \n",
    "        if self.return_filename:\n",
    "            return torch.FloatTensor((img - 128) / 128), filename\n",
    "        else:\n",
    "            return torch.FloatTensor((img - 128) / 128), alphabets2index[label]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downsample(in_ch, out_ch, stride):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(in_ch, out_ch, kernel_size=(1, 1), stride=stride, bias=False),\n",
    "        nn.BatchNorm2d(out_ch))\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    '''\n",
    "    input -> con2d(3x3) -> BN -> activation -> con2d(3x3) -> BN -> activation -> output\n",
    "    Perform downsampling directly by convolutional layers that have a stride of 2\n",
    "    '''\n",
    "    def __init__(self, in_ch, out_ch, downsample_stride):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        if downsample_stride is None:\n",
    "            self.conv1 = nn.Conv2d(in_ch, out_ch, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
    "            self.downsample = None\n",
    "        else:\n",
    "            self.conv1 = nn.Conv2d(in_ch, out_ch, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
    "            self.downsample = downsample(in_ch, out_ch, downsample_stride)\n",
    "        self.bn1 = nn.BatchNorm2d(out_ch)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv2d(out_ch, out_ch, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_ch)\n",
    "\n",
    "    def forward(self, x):\n",
    "        ori = x\n",
    "        out = self.bn1(self.conv1(x))\n",
    "        out = self.relu(out)\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        if self.downsample is not None:\n",
    "            ori = self.downsample(ori)\n",
    "        out = self.relu(out+ori)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet18(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ResNet18, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.layer1 = nn.Sequential(\n",
    "            BasicBlock(64, 64, None),\n",
    "            BasicBlock(64, 64, None)\n",
    "        )\n",
    "        self.layer2 = nn.Sequential(\n",
    "            BasicBlock(64, 128, (2, 2)),\n",
    "            BasicBlock(128, 128, None)\n",
    "        )\n",
    "        self.layer3 = nn.Sequential(\n",
    "            BasicBlock(128, 256, (2, 2)),\n",
    "            BasicBlock(256, 256, None)\n",
    "        )\n",
    "        self.layer4 = nn.Sequential(\n",
    "            BasicBlock(256, 512, (2, 2)),\n",
    "            BasicBlock(512, 512, None)\n",
    "        )\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d(output_size=(1, 1))\n",
    "        self.fc = nn.Linear(512, len(alphabets))\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.bn1(self.conv1(x))\n",
    "        out = self.relu(out)\n",
    "        out = self.maxpool(out)\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = self.avgpool(out)\n",
    "        out = self.fc(out.reshape(out.shape[0], -1))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNet18().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('./model_weights/task1.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 204/204 [06:57<00:00,  2.05s/it]\n"
     ]
    }
   ],
   "source": [
    "test_data = []\n",
    "with open('./dataset/sample_submission.csv', newline='') as csvfile:\n",
    "    for row in csv.reader(csvfile, delimiter=','):\n",
    "        test_data.append(row)\n",
    "\n",
    "test_ds = Task1Dataset(test_data, root=TEST_PATH, return_filename=True)\n",
    "test_dl = DataLoader(test_ds, batch_size=32, num_workers=0, drop_last=False, shuffle=False)\n",
    "\n",
    "\n",
    "if os.path.exists('submission.csv'):\n",
    "    csv_writer = csv.writer(open('submission.csv', 'a', newline=''))\n",
    "else:\n",
    "    csv_writer = csv.writer(open('submission.csv', 'w', newline=''))\n",
    "    csv_writer.writerow([\"filename\", \"label\"])\n",
    "\n",
    "\n",
    "model.eval()\n",
    "batch_pbar = tqdm(test_dl)\n",
    "for image, filenames in batch_pbar:\n",
    "    image = image.to(device)\n",
    "    \n",
    "    pred = model(image)\n",
    "    pred = torch.argmax(pred, dim=1)\n",
    "    \n",
    "    for i in range(len(filenames)):\n",
    "        csv_writer.writerow([filenames[i], alphabets[pred[i].item()]])\n",
    "\n",
    "# for filename, _ in test_data:\n",
    "#     if filename.startswith(\"task2\") or filename.startswith(\"task3\"):\n",
    "#         csv_writer.writerow([filename, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Task2Dataset(Dataset):\n",
    "    def __init__(self, data, root, return_filename=False):\n",
    "        self.data = [sample for sample in data if sample[0].startswith(\"task2\")]\n",
    "        self.return_filename = return_filename\n",
    "        self.root = root\n",
    "        self.transform = transforms.Compose([\n",
    "            #transforms.Resize(32),\n",
    "            transforms.ToTensor()\n",
    "        ])\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        filename, label = self.data[index]\n",
    "        img = cv2.imread(\"{}/{}\".format(self.root, filename))\n",
    "        img = cv2.resize(img, (96, 96))\n",
    "        img = cv2.medianBlur(img, 5)\n",
    "        img = np.mean(img, axis=2)\n",
    "        img = Image.fromarray(img)\n",
    "        img = self.transform(img)\n",
    "        \n",
    "        label_list = [[alphabets2index[digit]] for digit in label]\n",
    "        label_list = np.array(label_list)\n",
    "        #print(label_list)\n",
    "        \n",
    "        length = [len(label_list)]\n",
    "        \n",
    "        #label_list = [length] + label_list\n",
    "        label_list = np.append([length], label_list, axis=0)\n",
    "        \n",
    "        if self.return_filename:\n",
    "            return torch.FloatTensor((img - 128) / 128), filename\n",
    "        else:\n",
    "            return torch.FloatTensor((img - 128) / 128), label_list\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet18_t2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ResNet18_t2, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.layer1 = nn.Sequential(\n",
    "            BasicBlock(64, 64, None),\n",
    "            BasicBlock(64, 64, None)\n",
    "        )\n",
    "        self.layer2 = nn.Sequential(\n",
    "            BasicBlock(64, 128, (2, 2)),\n",
    "            BasicBlock(128, 128, None)\n",
    "        )\n",
    "        self.layer3 = nn.Sequential(\n",
    "            BasicBlock(128, 256, (2, 2)),\n",
    "            BasicBlock(256, 256, None)\n",
    "        )\n",
    "        self.layer4 = nn.Sequential(\n",
    "            BasicBlock(256, 512, (2, 2)),\n",
    "            BasicBlock(512, 512, None)\n",
    "        )\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d(output_size=(1, 1))\n",
    "        self.digitlength = nn.Linear(512, 1)\n",
    "        self.digit1 = nn.Linear(512, len(alphabets))\n",
    "        self.digit2 = nn.Linear(512, len(alphabets))\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.bn1(self.conv1(x))\n",
    "        out = self.relu(out)\n",
    "        out = self.maxpool(out)\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = self.avgpool(out)\n",
    "        yl = self.digitlength(out.reshape(out.shape[0], -1))\n",
    "        y1 = self.digit1(out.reshape(out.shape[0], -1))\n",
    "        y2 = self.digit2(out.reshape(out.shape[0], -1))\n",
    "        #out = self.fc(out.reshape(out.shape[0], -1))\n",
    "        return [yl, y1, y2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNet18_t2().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('./model_weights/task2.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 2500/2500 [05:24<00:00,  7.71it/s]\n"
     ]
    }
   ],
   "source": [
    "test_data = []\n",
    "with open('./dataset/sample_submission.csv', newline='') as csvfile:\n",
    "    for row in csv.reader(csvfile, delimiter=','):\n",
    "        test_data.append(row)\n",
    "\n",
    "test_ds = Task2Dataset(test_data, root=TEST_PATH, return_filename=True)\n",
    "test_dl = DataLoader(test_ds, batch_size=1, num_workers=0, drop_last=False, shuffle=False)\n",
    "\n",
    "\n",
    "if os.path.exists('submission.csv'):\n",
    "    csv_writer = csv.writer(open('submission.csv', 'a', newline=''))\n",
    "else:\n",
    "    csv_writer = csv.writer(open('submission.csv', 'w', newline=''))\n",
    "    csv_writer.writerow([\"filename\", \"label\"])\n",
    "\n",
    "\n",
    "model.eval()\n",
    "batch_pbar = tqdm(test_dl)\n",
    "for image, filenames in batch_pbar:\n",
    "    image = image.to(device)\n",
    "    \n",
    "    outputs = model(image)\n",
    "        \n",
    "    pred1 = torch.argmax(outputs[1])\n",
    "    pred2 = torch.argmax(outputs[2])\n",
    "\n",
    "    pred2str_first = alphabets[pred1]\n",
    "    pred2str_second = alphabets[pred2]\n",
    "\n",
    "    res = pred2str_first + pred2str_second\n",
    "    \n",
    "    filenames = ''.join(filenames)\n",
    "    #print(filenames)\n",
    "    \n",
    "    csv_writer.writerow([filenames, res])\n",
    "\n",
    "# for filename, _ in test_data:\n",
    "#     if filename.startswith(\"task3\"):\n",
    "#         csv_writer.writerow([filename, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Task3Dataset(Dataset):\n",
    "    def __init__(self, data, root, return_filename=False):\n",
    "        self.data = [sample for sample in data if sample[0].startswith(\"task3\")]\n",
    "        self.return_filename = return_filename\n",
    "        self.root = root\n",
    "        \n",
    "        self.transform = transforms.Compose([\n",
    "            #transforms.Resize(32),\n",
    "            transforms.ToTensor()\n",
    "        ])\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        filename, label = self.data[index]\n",
    "        img = cv2.imread(\"{}/{}\".format(self.root, filename))\n",
    "        img = cv2.resize(img, (96, 96))\n",
    "        img = cv2.medianBlur(img, 5)\n",
    "        img = np.mean(img, axis=2)\n",
    "        img = Image.fromarray(img)\n",
    "        img = self.transform(img)\n",
    "        \n",
    "        label_list = [[alphabets2index[digit]] for digit in label]\n",
    "        label_list = np.array(label_list)\n",
    "        #print(label_list)\n",
    "        \n",
    "        length = [len(label_list)]\n",
    "        \n",
    "        #label_list = [length] + label_list\n",
    "        label_list = np.append([length], label_list, axis=0)\n",
    "        \n",
    "        if self.return_filename:\n",
    "            return torch.FloatTensor((img - 128) / 128), filename\n",
    "        else:\n",
    "            return torch.FloatTensor((img - 128) / 128), label_list\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet18_t3(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ResNet18_t3, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.layer1 = nn.Sequential(\n",
    "            BasicBlock(64, 64, None),\n",
    "            BasicBlock(64, 64, None)\n",
    "        )\n",
    "        self.layer2 = nn.Sequential(\n",
    "            BasicBlock(64, 128, (2, 2)),\n",
    "            BasicBlock(128, 128, None)\n",
    "        )\n",
    "        self.layer3 = nn.Sequential(\n",
    "            BasicBlock(128, 256, (2, 2)),\n",
    "            BasicBlock(256, 256, None)\n",
    "        )\n",
    "        self.layer4 = nn.Sequential(\n",
    "            BasicBlock(256, 512, (2, 2)),\n",
    "            BasicBlock(512, 512, None)\n",
    "        )\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d(output_size=(1, 1))\n",
    "        self.digitlength = nn.Linear(512, 1)\n",
    "        self.digit1 = nn.Linear(512, len(alphabets))\n",
    "        self.digit2 = nn.Linear(512, len(alphabets))\n",
    "        self.digit3 = nn.Linear(512, len(alphabets))\n",
    "        self.digit4 = nn.Linear(512, len(alphabets))\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.bn1(self.conv1(x))\n",
    "        out = self.relu(out)\n",
    "        out = self.maxpool(out)\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = self.avgpool(out)\n",
    "        yl = self.digitlength(out.reshape(out.shape[0], -1))\n",
    "        y1 = self.digit1(out.reshape(out.shape[0], -1))\n",
    "        y2 = self.digit2(out.reshape(out.shape[0], -1))\n",
    "        y3 = self.digit3(out.reshape(out.shape[0], -1))\n",
    "        y4 = self.digit4(out.reshape(out.shape[0], -1))\n",
    "        return [yl, y1, y2, y3, y4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNet18_t3().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('./model_weights/task3.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:13<00:00, 74.88it/s]\n"
     ]
    }
   ],
   "source": [
    "test_data = []\n",
    "with open('./dataset/sample_submission.csv', newline='') as csvfile:\n",
    "    for row in csv.reader(csvfile, delimiter=','):\n",
    "        test_data.append(row)\n",
    "\n",
    "test_ds = Task3Dataset(test_data, root=TEST_PATH, return_filename=True)\n",
    "test_dl = DataLoader(test_ds, batch_size=1, num_workers=0, drop_last=False, shuffle=False)\n",
    "\n",
    "\n",
    "if os.path.exists('submission.csv'):\n",
    "    csv_writer = csv.writer(open('submission.csv', 'a', newline=''))\n",
    "else:\n",
    "    csv_writer = csv.writer(open('submission.csv', 'w', newline=''))\n",
    "    csv_writer.writerow([\"filename\", \"label\"])\n",
    "\n",
    "\n",
    "model.eval()\n",
    "batch_pbar = tqdm(test_dl)\n",
    "for image, filenames in batch_pbar:\n",
    "    image = image.to(device)\n",
    "    \n",
    "    outputs = model(image)\n",
    "        \n",
    "    pred1 = torch.argmax(outputs[1])\n",
    "    pred2 = torch.argmax(outputs[2])\n",
    "    pred3 = torch.argmax(outputs[3])\n",
    "    pred4 = torch.argmax(outputs[4])\n",
    "\n",
    "    pred2str_first = alphabets[pred1]\n",
    "    pred2str_second = alphabets[pred2]\n",
    "    pred2str_third = alphabets[pred3]\n",
    "    pred2str_fourth = alphabets[pred4]\n",
    "\n",
    "    res = pred2str_first + pred2str_second + pred2str_third + pred2str_fourth\n",
    "    \n",
    "    filenames = ''.join(filenames)\n",
    "    #print(filenames)\n",
    "    \n",
    "    csv_writer.writerow([filenames, res])\n",
    "\n",
    "# for filename, _ in test_data:\n",
    "#     if filename.startswith(\"task3\"):\n",
    "#         csv_writer.writerow([filename, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
